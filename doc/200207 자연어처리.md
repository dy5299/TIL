# 자연어 처리 (NLP)

컴퓨터 과학, 인공지능, 언어학이 합쳐진 분야이다.



#### 자연어 처리 업무

난이도 쉬움:	스펠링 체크, 키워드 검사, 유사어 감지

난이도 중간:	웹사이트 및 서류의 형태 해석, 구문해석

​							ex) 영수증 해석

난이도 어려움:기계번역, 감정분석, 질의응답 시스템



#### 자연어 처리의 어려움

언어,상황,환경,지각 지식의 학습 및 표현의 복잡함 -> Rule 기반만으로는 무리인가?

영상은 벡터로 분석, 수치화 가능했다. 그런데 언어는? 기존의 알고리즘을 적용하기 어렵다.

DNN은 분산표현의 장점으로 인해 모호하지만 풍부한 정보를 얻을 수 있다. -> 단어의 벡터화로부터 시작

## 언어 데이터의 특성

불연속적인 심볼의 sequence			(영상, 음성은 연속적이다. Text는 불연속적)

계열 길이가 샘플에 따라 다르다

계층적, 재귀적인 구조를 지닌다. (문자, 단어, 구, 문)



1. 계열 -> 계열
   - 형태소 해석
   - 기계번역, 자동요약
   - 질의응답, 챗봇
2. 계열 -> tree 구조                    초반에 많이 했던 것. 어렵다. 알고리즘 보진 않을 거고 갖다 쓸 거야.
   - 구문 해석
3. 계열 -> 그래프 구조                연구가 많이 이뤄지고 있진 않다. 문맥을 이해하는 부분.
   - 의미해석

단어의 국소표현: 단어를 벡터로 (one-hot encoding과 비슷) 한다면 -> 단어의 의미를 파악하는 벡터가 필요, 차원이 매우 커진다.

### 분포가설

비슷한 문맥을 가진 단어는 비슷한 의미를 가진다. = 현대의 통계적 자연어 처리에서 획기적인 발상

크게 2종류이다.

- count-based methods
  - ex) SVD(LSA), HAL
  - 단어, 문맥 **출현 횟수를 세는** 방법

- predictive methods
  - ex) NPLM, ...
  - 학습을 해서(특징을 만듦) 연산도 가능(단어 간 거리 측정 가능), 예측하는...

자연어 처리의 기반은 rule base이다.

규칙을 이용한 학습.

가위바위보 규칙

`-1 % 3` = `(-1+3) % 3` = 2

0:비김, 1:이김, 2:짐







```python
pip install gensim			#단어들을 벡터로 만드는 알고리즘
pip install wordcloud		#구름 그리기
pip install konlpy --user	#한국어 형태소 분석
pip install jpype1		#윈도우에서 안 돼서 아래 라인 코드로 설치
conda install -c conda -forge jpype1	#depending konlpy library. 자바기반. ----- 오류남
```

언어마다 히스토그램을 분석하여

각 캐릭터의 분포를 구한다 - 특정 코드의 빈도수를 계산하는 방법

유니코드는 9byte. 코드가 0~65535번까지 있다.

`ord()` : 아스키코드(쉽게 생각해서 유니코드)로 변환

주어진 문장에 대해 히스토그램이 계산된다.

