{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "얼굴인식하고  \n",
    "age, gender 나오고  \n",
    "DNN?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imutils  import face_utils\n",
    "import numpy as np\n",
    "import imutils\n",
    "import dlib #얼굴검출기가 별도로 있어\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import face_recognition #인식+검출기\n",
    "import os\n",
    "from imutils import paths\n",
    "import math\n",
    "import time\n",
    "\n",
    "def imshow(tit, image) :\n",
    "    plt.title(tit)    \n",
    "    if len(image.shape) == 3 :\n",
    "        plt.imshow(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))\n",
    "    else :\n",
    "        plt.imshow(image, cmap=\"gray\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getFaceBox(net, frame, conf_threshold=0.7):\n",
    "    frameOpencvDnn = frame.copy()\n",
    "    frameHeight = frameOpencvDnn.shape[0]\n",
    "    frameWidth = frameOpencvDnn.shape[1]\n",
    "    blob = cv2.dnn.blobFromImage(frameOpencvDnn, 1.0, (300, 300), [104, 117, 123], True, False)\n",
    "\n",
    "    net.setInput(blob)\n",
    "    detections = net.forward()\n",
    "    bboxes = []\n",
    "    for i in range(detections.shape[2]):\n",
    "        confidence = detections[0, 0, i, 2]\n",
    "        if confidence > conf_threshold:\n",
    "            x1 = int(detections[0, 0, i, 3] * frameWidth)\n",
    "            y1 = int(detections[0, 0, i, 4] * frameHeight)\n",
    "            x2 = int(detections[0, 0, i, 5] * frameWidth)\n",
    "            y2 = int(detections[0, 0, i, 6] * frameHeight)\n",
    "            bboxes.append([x1, y1, x2, y2])\n",
    "            cv2.rectangle(frameOpencvDnn, (x1, y1), (x2, y2), (0, 255, 0), int(round(frameHeight/150)), 8)\n",
    "    return frameOpencvDnn, bboxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread(\"img/tes.jpg\")\n",
    "detection_model_path = 'haarcascade_frontalface_alt2.xml'\n",
    "emotion_model_path = 'fer2013_big_XCEPTION.54-0.66.hdf5'\n",
    "emotion_model_path = \"../../../../emotion_temp.h5\"\n",
    "emotion_labels = {0:'angry',1:'disgust',2:'fear',3:'happy',4:'sad',5:'surprise',6:'neutral'}\n",
    "font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "\n",
    "emotion_offsets = (0, 0)\n",
    "\n",
    "# loading models\n",
    "face_detection = detection_model = cv2.CascadeClassifier(detection_model_path)\n",
    "emotion_classifier = load_model(emotion_model_path, compile=False)\n",
    "emotion_target_size = emotion_classifier.input_shape[1:3]\n",
    "\n",
    "\n",
    "\n",
    "face_locations = face_recognition.face_locations(img) #HOG algorithm\n",
    "\n",
    "for face_location in face_locations:\n",
    "    top, right, bottom, left = face_location\n",
    "    cv2.rectangle(img, (left,top), (right,bottom),(0,0,255),3)\n",
    "imshow(\"\",img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading images\n",
    "rgb_image = cv2.imread(\"img/tes.jpg\")\n",
    "gray_image = cv2.imread(\"img/tes.jpg\",0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_offsets(face_coordinates, offsets):\n",
    "    x, y, width, height = face_coordinates\n",
    "    x_off, y_off = offsets\n",
    "    return (x - x_off, x + width + x_off, y - y_off, y + height + y_off)\n",
    "\n",
    "\n",
    "    \n",
    "def preprocess_input(x, v2=True):\n",
    "    x = x.astype('float32')\n",
    "    x = x / 255.0\n",
    "    if v2:\n",
    "        x = x - 0.5\n",
    "        x = x * 2.0\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "face_detection.detectMultiScale(gray_image, 1.3, 5)\n",
    "\n",
    "for face_coordinates in faces:   \n",
    "    \n",
    "    x1, x2, y1, y2 = apply_offsets(face_coordinates, emotion_offsets)\n",
    "    gray_face = gray_image[y1:y2, x1:x2]\n",
    "\n",
    "    gray_face = cv2.resize(gray_face, (emotion_target_size))\n",
    "\n",
    "    gray_face = preprocess_input(gray_face, True)\n",
    "    gray_face = np.expand_dims(gray_face, 0) # 앞에 1차원 추가    2x2가 48x48x1 (shape만 변함, data는 그대로)\n",
    "    gray_face = np.expand_dims(gray_face, -1) # 뒤에 1차원 추가\n",
    "    \n",
    "    emotion_label_arg = np.argmax(emotion_classifier.predict(gray_face))\n",
    "    emotion_text = emotion_labels[emotion_label_arg]\n",
    "    \n",
    "    color = (255, 0, 0)\n",
    "    \n",
    "    #draw bounding box\n",
    "    x, y, w, h = face_coordinates\n",
    "    cv2.rectangle(rgb_image, (x, y), (x + w, y + h), color, 2)\n",
    "    \n",
    "    #draw text\n",
    "    x_offset = -20\n",
    "    y_offset = -20\n",
    "    font_scale = 0.7\n",
    "    thickness = 2\n",
    "    x, y = face_coordinates[:2]\n",
    "    cv2.putText(rgb_image, emotion_text, (x + x_offset, y + y_offset),\n",
    "                cv2.FONT_HERSHEY_SIMPLEX,\n",
    "                font_scale, color, thickness, cv2.LINE_AA)\n",
    "    \n",
    "#cv2.imwrite('out.jpg', rgb_image)\n",
    "imshow(\"\",rgb_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
