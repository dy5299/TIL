{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep Learning\n",
    "머신러닝 교과서 chap.2, 12~15\n",
    "케라스딥러닝 chap.1 머신러닝 이론 개괄\n",
    "\n",
    "### 인공 지능과 머신 러닝, 딥 러닝의 차이점\n",
    "#### 인공 지능\n",
    "* 인공 지능 - 1956년 미국 다트머스 대학에 있던 존 매카시 교수가 개최한 다트머스 회의에서 처음 등장\n",
    "* 2015년 이후 신속하고 강력한 병렬 처리 성능을 제공하는 GPU의 도입으로  인공지능의 성장세 가속화 - 폭발적으로 늘어나고 있는 저장 용량과 이미지, 텍스트, 매핑 데이터 등 모든 영역의 데이터가 범람하게 된 ‘빅데이터’가 인공지능의 성장세에 큰 영향을 줌\n",
    "* 인간이 지닌 지적 능력을 인공적으로 구현한 것\n",
    "* 기계 혹은 시스템에 의해 만들어진 지능General AI - 인간의 감각, 사고력을 지닌 채 인간처럼 생각하는 인공 지능\n",
    "* Narrow AI - 소셜 미디어의 이미지 분류 서비스나 얼굴 인식 기능 등과 같이 특정 작업을 인간 이상의 능력으로 해낼 수 있는 것\n",
    "* 인간의 학습능력, 추론능력, 지각능력, \u000b",
    "자연언어 등의 이해능력을 컴퓨터 \u000b",
    "프로그래밍으로 구현한 기술\n",
    "#### 머신 러닝\n",
    "* 알고리즘을 이용해 데이터를 분석하고, 분석을 통해 학습하며, 학습한 내용을 기반으로 판단이나 예측을 합니다. \n",
    "* 궁극적으로는 의사 결정 기준에 대한 구체적인 지침을 소프트웨어에 직접 코딩해 넣는 것이 아닌, 대량의 데이터와 알고리즘을 통해 컴퓨터 그 자체를 ‘학습’시켜 작업 수행 방법을 익히는 것을 목표로 함\n",
    "* 알고리즘 방식 - 의사 결정 트리 학습, 귀납 논리 프로그래밍, 클러스터링, 강화 학습, 베이지안(Bayesian) 네트워크 등이 포함\n",
    "* 인공지능의 한 분야로서 빅데이터를 분석하고 \u000b",
    "가공해서 새로운 정보를 얻어 내거나 미래를 예측하는 기술\n",
    "* 인공지능의 하위 분야\n",
    "* 기계가 직접 데이터를 학습(러닝)함으로써 그 속에 \u000b",
    "숨겨진 일련의 규칙성을 찾는다\n",
    "* 예] 문자인식, 음성인식, 바둑 또는 장기 등의 게임 전략\u000b",
    ", 의료 진단, 로봇개발\n",
    "#### 머신 러닝 응용분야\n",
    "* 클래스 분류(Classification)\n",
    "* 클러스터링 – 그룹 나누기(Clustering)\n",
    "* 추천(Recommendation)\n",
    "* 회귀(Regression)\n",
    "* 차원 축소(Dimensionality Reduction) – 특성을 유지한 상태로 고차원의 데이터를 저차원의 데이터로 변환하는 것\n",
    "데이터를 시각화하거나 구조를 추출해서 용량을 줄여 계산을 빠르게 하거나 메모리를 절약할때 사용\n",
    "* 초과 적합(Overfitting) – 훈련 전용 데이터가 학습돼 있지만 학습되지 않은 새로운 데이터에 대해 제대로 된 예측을 못하는 상태\n",
    "#### 딥러닝(심층학습, 강화학습) \n",
    "* 여러 층을 가진  인공신경망을 이용하여 머신러닝을 수행하는 것\n",
    "* 인공신경망을 넓고 다층(Deep)으로 쌓으면 딥러닝(Deep-Learning)\n",
    "* 신경망을 사용해 수많은 데이터 속에서 어떤 패턴을 파악하고 이것을 통해 인간이 사물을 구분하듯이 컴퓨터가 데이터를 나누는 것 (사물이나 데이터를 군집화 하거나 분류할 때 사용)\n",
    "* 데이터 자체를 컴퓨터에게 전달,  인공신경망 구조를 사용하여 데이터 전체를 학습시킨다 (인간의 뇌에서 일어나는 의사결정 과정을 모방한 인공신경망(Artificial Neural Network) 구조를 통해서 학습한다)\n",
    "* 예]  컴퓨터에 개와 고양이 사진을 학습시켜 특정사진의 동물이 개인지 고양이인지 분류\n",
    "일반적인 기계학습의 경우 개와 고양이의 구별되는 큰 특징들만 뽑아 컴퓨터에게 전달) 딥러닝은 개, 고양이 사진 자체를 컴퓨터가 학습하도록 하는 것\n",
    "#### 인공 지능과 머신 러닝, 딥 러닝의 차이점\n",
    "딥러닝 단계에서 군집화된 데이터를 분류 → 머신러닝 단계를 거쳐 학습 → 인공지능의 단계에서는 어떤 판단이나 결과를 내는 과정\n",
    "#### AI의 패러다임\n",
    "* 심볼릭 AI의 패러다임 - 규칙(프로그램)과 이 규칙에 따라 처리될 데이터를 입력하면 해답이 출력\n",
    "* 머신 러닝 - 데이터와 데이터로부터 기대되는 해답을 입력하면 규칙이 출력\n",
    "* 머신러닝은 데이터에서 통계적 구조를 찾아 그 작업을 자동화하기 위한 규칙을 만들어 냅니다. (학습)\n",
    "* 머신 러닝 모델은 입력 데이터를 기반으로 기대 출력에 가깝게 만드는 유용한 표현(representation)을 학습하는 것\n",
    "* 머신 러닝에서의 학습(Learning)이란 더 나은 표현을 찾는 자동화된 과정입니다.\n",
    "* 모든 머신 러닝 알고리즘은 주어진 작업을 위해 데이터를 더 유용한 표현으로 바꾸는 이런 변환을 자동으로 찾습니다.\n",
    "* 머신 러닝 연산 - 선형 투영(linear projection)(정보를 잃을 수 있음), 이동(translation), 비선형 연산(예를 들어 x > 0인 모든 포인트를 선택하는 것) 등\n",
    "* 가설 공간(hypothesis space)이라 부르는 미리 정의된 연산의 모음들을 자세히 조사하는 것\n",
    "* 머신 러닝은 가능성 있는 공간을 사전에 정의하고 피드백 신호의 도움을 받아 입력 데이터에 대한 유용한 변환을 찾는 것\n",
    "#### 흰색 포인트와 검은색 포인트의 좌표 (x, y)를 입력으로 받고, 포인트가 검은색인지 흰색인지를 출력하는 알고리즘을 개발  \n",
    "* 입력은 포인트의 좌표 \n",
    "* 기대 출력은 포인트의 색깔\n",
    "* 알고리즘의 성능을 측정하는 방법은 정확히 분류한 포인트의 비율을 사용하여 알고리즘의 성능을 측정\n",
    "#### 딥러닝   \n",
    "* 기본 층을 겹겹이 쌓아 올려 구성한 신경망(neural network)이라는 모델을 사용하여 표현 층을 학습\n",
    "* 층 기반 표현 학습(layered representations learning) 또는 계층적 표현 학습(hierarchical representations learning)\n",
    "#### 깊은 신경망(Deep Neural Network : DNN)   \n",
    "* 신경망을 3개 이상 중첩\n",
    "\n",
    "\n",
    "### 환경설정 및 라이브러리\n",
    "#### 딥러닝 라이브러리   \n",
    "* 케라스(keras)를 사용해 딥러닝을 실행시킵니다. \n",
    "* 케라스가 구동되려면 텐서플로(TensorFlow) 또는 씨아노(theano)라는 두 가지 라이브러리 중 하나가 미리 설치되어 있어야 합니다\n",
    "\n",
    "keras 라이브러리 - Sequential() 와 Dense()   \n",
    "* Sequential() - 딥러닝의 구조를 한 층 한 층 쉽게 쌓아올릴 수 있게 해 줍니다. \n",
    "* Sequential 함수를 선언하고 나서 model.add() 함수를 사용해 필요한 층을 차례로 추가합니다.\n",
    "* Dense( activation=, loss=, optimizer=) 각 층이 제각각 어떤 특성을 가질지 옵션을 설정하는 역할을 합니다.\n",
    "activation: 다음 층으로 어떻게 값을 넘길지 결정하는 부분(가장 많이 사용되는 relu와 sigmoid 함수)\n",
    "loss: 한 번 신경망이 실행될 때마다 오차 값을 추적하는 함수\n",
    "optimizer: 오차를 어떻게 줄여 나갈지 정하는 함수\n",
    "* model.evaluate() - 딥러닝의 모델이 어느 정도 정확하게 예측하는지를 점검\n",
    "\n",
    "\n",
    "## TensorFlow 모듈\n",
    "* 구글이 공개한 대규모 숫자 계산을 해주는  머신러닝 및 딥러닝 전문 라이브러리\n",
    "* Tensor는 다차원 행렬 계산을 의미\n",
    "* 상업적인 용도로 사용할 수 있는 오픈소스(Apache 2.0)\n",
    "* C++로 만들어진 라이브러리\n",
    "* 파이썬을 사용해서 호출할 때 오버헤드가 거의 없는 구조로 설계\n",
    "* https://www.tensorflow.org\n",
    "* 이미지 처리와 음향 처리 등을 할 때는 추가적으로 이미지 처리에 특화된 OpenCV 라이브러리등과 함께 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting keras\n",
      "  Downloading https://files.pythonhosted.org/packages/ad/fd/6bfe87920d7f4fd475acd28500a42482b6b84479832bdc0fe9e589a60ceb/Keras-2.3.1-py2.py3-none-any.whl (377kB)\n",
      "Requirement already satisfied: pyyaml in c:\\users\\student\\anaconda3\\lib\\site-packages (from keras) (5.1.2)\n",
      "Requirement already satisfied: keras-applications>=1.0.6 in c:\\users\\student\\anaconda3\\lib\\site-packages (from keras) (1.0.8)\n",
      "Requirement already satisfied: scipy>=0.14 in c:\\users\\student\\anaconda3\\lib\\site-packages (from keras) (1.3.1)\n",
      "Requirement already satisfied: numpy>=1.9.1 in c:\\users\\student\\anaconda3\\lib\\site-packages (from keras) (1.16.5)\n",
      "Requirement already satisfied: keras-preprocessing>=1.0.5 in c:\\users\\student\\anaconda3\\lib\\site-packages (from keras) (1.1.0)\n",
      "Requirement already satisfied: six>=1.9.0 in c:\\users\\student\\anaconda3\\lib\\site-packages (from keras) (1.12.0)\n",
      "Requirement already satisfied: h5py in c:\\users\\student\\anaconda3\\lib\\site-packages (from keras) (2.9.0)\n",
      "Installing collected packages: keras\n",
      "Successfully installed keras-2.3.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.0.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip uninstall tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install tensorflow == 1.15"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 상수 지정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\student\\Anaconda3\\envs\\test\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6234\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "#상수 정의\n",
    "a = tf.constant(1234)\n",
    "b = tf.constant(5000)\n",
    "\n",
    "#계산 정의\n",
    "add_op = a+b\n",
    "\n",
    "#세션 시작\n",
    "sess = tf.Session()\n",
    "res = sess.run(add_op)\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14\n",
      "20\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "#상수 정의\n",
    "a = tf.constant(2)\n",
    "b = tf.constant(3)\n",
    "c = tf.constant(4)\n",
    "\n",
    "#계산 정의\n",
    "calc1_op = a+b*c\n",
    "calc2_op = (a+b)*c\n",
    "\n",
    "#세션 시작\n",
    "sess = tf.Session()\n",
    "res1 = sess.run(calc1_op)\n",
    "print(res1)\n",
    "res2 = sess.run(calc2_op)\n",
    "print(res2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "150\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "#상수 정의\n",
    "a = tf.constant(100) \n",
    "b = tf.constant(50)\n",
    "add_op = a+ b\n",
    "\n",
    "#변수 v 선언하기\n",
    "v = tf.Variable(0)\n",
    "\n",
    "#세션 시작 \n",
    "sess = tf.Session() \n",
    "# 변수 초기화히기\n",
    "# 변수는 초기화하지 않으면 사용할 수 없다. 반드시 initialization 하여야 한다.\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "# 변수 v에 add_op의 결과 대입하기\n",
    "let_op = tf.assign(v, add_op) #assign이 변수의 초기값을 설정하는 것\n",
    "\n",
    "#계산식 실행\n",
    "sess.run(let_op) \n",
    "print(sess.run(v))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Placeholder\n",
    "* 템플릿처럼 값을 넣을 공간을 만들어두는 기능\n",
    "* 데이터 플로우 그래프를 구축할 때는 값을 넣지 않고 값을 담을 수 있는 그릇만 만들어두고, 이후에 세션을 실행할 때 그릇에 값을 넣고 실행할 수 있습니다\n",
    "\n",
    "##### 배열 갯수 고정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2 4 6]\n",
      "[20 40 20]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "#placeholder 정의 - 정수 자료형 3개를 가진 배열\n",
    "a = tf.placeholder(tf.int32, [3])\n",
    "b = tf.constant(2)\n",
    "x2_op = a*b\n",
    "\n",
    "#세션 시작\n",
    "sess = tf.Session()\n",
    "#placeholder에 값 넣고 실행하기\n",
    "r1 = sess.run(x2_op, feed_dict = {a:[1,2,3]})\n",
    "print(r1)\n",
    "r2 = sess.run(x2_op, feed_dict = {a:[10,20,10]})\n",
    "print(r2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 배열 갯수 가변"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10 20 30 40 50]\n",
      "[100 200]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "#placeholder 정의( 배열의 크기를 None으로 지정)\n",
    "a = tf.placeholder(tf.int32, [None])\n",
    "b = tf.constant(10)\n",
    "x10_op = a*b\n",
    "\n",
    "#세션 시작 \n",
    "sess = tf.Session()\n",
    "# placeholder에 값 넣고 실행하기\n",
    "r1 = sess.run(x10_op, feed_dict = {a:[1,2,3,4,5]})\n",
    "print(r1)\n",
    "r2 = sess.run(x10_op, feed_dict = {a:[10,20]})\n",
    "print(r2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "SVM(Supprt Vector Machine)으로 BMI 판정\n",
    "키의 최대값은 200cm, 몸무게의 최대값은 100kg으로 정규화\n",
    "저체중(thin), 정상(normal), 비만(fat) 레이블을 one-hot-encoding [1, 0, 0], [0, 1, 0], [0, 0, 1]로 변환\n",
    "소프트 맥스 회귀방법 , 오차 함수는 교차 엔트로피 사용\n",
    "교차 엔트로피  - 2개의 확률 분포 사이에 정의되는 척도로서 교차 엔트로피 값이 작을 수록 정확한 값을 냄\n",
    "학습 계수 0.01, 경사 하강법(steepest descent method) 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "# 키, 몸무게, 레이블이 적힌 CSV 파일 읽어 들이기 \n",
    "csv = pd.read_csv(\"bmi.csv\")\n",
    "# 데이터 정규화 \n",
    " \n",
    "# 레이블을 배열로 변환하기 - thin=(1,0,0) / normal=(0,1,0) / fat=(0,0,1)\n",
    " \n",
    "# 테스트를 위한 데이터 분류 \n",
    "\n",
    "# 데이터 플로우 그래프 구축하기 \n",
    "# 플레이스홀더 선언하기\n",
    " \n",
    "# 변수 선언하기 \n",
    " \n",
    "# 소프트맥스 회귀 정의하기 \n",
    " \n",
    "# 모델 훈련하기 \n",
    " \n",
    "# 정답률 구하기\n",
    " \n",
    "# 세션 시작하기\n",
    " \n",
    " \n",
    "# 학습시키기\n",
    " \n",
    "# 최종적인 정답률 구하기\n",
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 데이터플로우 그래프 구축\n",
    "#플레이스홀더 선언\n",
    "x = tf.placeholder(tf.float32, [None, 2])\n",
    "y = tf.placeholder(tf.float32, [None, 3])\n",
    "#변 수선언\n",
    "W = tf.Variable(tf.zeros[2,3]) #가중치\n",
    "b = tf.Variable(tf.zeros[3]) #bais\n",
    "#소프트맥스 회귀 정의\n",
    "y= tf.nn.softmax(tf.matmul(x,W)+b)\n",
    "#모델 훈련\n",
    "cross_entropy = tf.reduce_sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TensorBoard\n",
    "* 데이터의 흐름을 시각화하는 도구\n",
    "* 로그 데이터를 저장할 폴더 준비 \n",
    "* tensorbord –logdir=로그데이터 저장폴더\n",
    "* Localhost:6006"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "600\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "# 데이터 플로우 그래프 구축하기  \n",
    "a = tf.constant(20, name=\"a\")\n",
    "b = tf.constant(30, name=\"b\")\n",
    "mul_op = a * b\n",
    "# 세션 생성하기  \n",
    "sess = tf.Session()\n",
    "# TensorBoard 사용하기  \n",
    "tw = tf.summary.FileWriter(\"log_dir\", graph=sess.graph)\n",
    "# 세션 실행하기 \n",
    "print(sess.run(mul_op))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "# 상수와 변수 선언하기  \n",
    "a = tf.constant(100, name=\"a\")\n",
    "b = tf.constant(200, name=\"b\")\n",
    "c = tf.constant(300, name=\"c\")\n",
    "v = tf.Variable(0, name=\"v\")\n",
    "# 곱셈을 수행하는 그래프 정의하기  \n",
    "calc_op = a + b * c \n",
    "assign_op = tf.assign(v, calc_op)\n",
    "# 세션 생성하기  \n",
    "sess = tf.Session()\n",
    "# TensorBoard 사용하기  \n",
    "tw = tf.summary.FileWriter(\"log_dir\", graph=sess.graph)\n",
    "# 세션 실행하기   \n",
    "sess.run(assign_op)\n",
    "print(sess.run(v))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BMI 판정\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "# 키, 몸무게, 레이블이 적힌 CSV 파일 읽어 들이기\n",
    "csv = pd.read_csv(\"bmi.csv\")\n",
    "# 데이터 정규화 \n",
    " \n",
    "# 레이블을 배열로 변환하기\n",
    " \n",
    "\n",
    "# 테스트를 위한 데이터 분류\n",
    " \n",
    "\n",
    "# 플레이스홀더로 이름 붙이기\n",
    " \n",
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# keras 이용 BMI 판정\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Dropout, Activation\n",
    "from keras.callbacks import EarlyStopping\n",
    "import pandas as pd, numpy as np\n",
    "# BMI 데이터를 읽어 들이고 정규화하기  \n",
    " \n",
    "# 몸무게와 키 데이터\n",
    " \n",
    "\n",
    "# 레이블\n",
    " \n",
    "# 훈련 전용 데이터와 테스트 전용 데이터로 나누기  \n",
    " \n",
    "# 모델 구조 정의하기  \n",
    " \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 딥러닝 동작 원리\n",
    "#### 선형 회귀(linear regression)   \n",
    "* 단순 선형 회귀(simple linear regression)  - 하나의 x 값만으로 y 값을 설명\n",
    "* 다중 선형 회귀(multiple linear regression) - 여러개의 x 값이 y 값을 설명\n",
    "* 선형 회귀는  정확한 직선을 그려내는 과정으로 직선의 기울기 a 값과 y 절편 b 값을 정확히 예측해 내야 하는 것\n",
    "\n",
    "산점도를 그려 선형인지 확인\n",
    "#### 최소 제곱법(method of least squares)   \n",
    "* 최소 제곱법 -  회귀 분석에서 사용되는 표준 방식\n",
    "* 실험이나 관찰을 통해 얻은 데이터를 분석하여 미지의 상수를 구할 때 사용되는 공식\n",
    "* 최소 제곱법을 통해 일차 함수의 기울기 a와 y 절편 b를  구할 수 있습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 최소 제곱법 공식으로 구한 성적 예측 코딩"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x의 평균값: 5.0\n",
      "y의 평균값: 90.5\n",
      "분모: 20.0\n",
      "분자: 46.0\n",
      "기울기: 2.3\n",
      "y절편: 79.0\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "x = [2,4,6,8]\n",
    "y = [81,93,91,97]\n",
    "\n",
    "mx = np.mean(x)\n",
    "my = np.mean(y)\n",
    "print(\"x의 평균값:\", mx)\n",
    "print(\"y의 평균값:\", my)\n",
    "\n",
    "divisor = sum([(mx-i)**2 for i in x]) #a 분모\n",
    "\n",
    "def top(x,mx,y,my) : #a 분자\n",
    "    d = 0\n",
    "    for i in range(len(x)):\n",
    "        d += (x[i] - mx) * (y[i]-my)\n",
    "    return d\n",
    "\n",
    "dividend = top(x,mx,y,my)\n",
    "print(\"분모:\", divisor)\n",
    "print(\"분자:\", dividend)\n",
    "\n",
    "a = dividend / divisor\n",
    "b = my - (mx*a)\n",
    "\n",
    "print(\"기울기:\",a)\n",
    "print(\"y절편:\",b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 평균 제곱근 오차(root mean square error)   \n",
    "* 딥러닝은 대부분 입력 값이 여러 개인 상황에서 이를 해결하기 위해 실행됩니다. \n",
    "* 여러 개의 입력 값을 계산할 때는 임의의 선을 그리고 난 후, 이 선이 얼마나 잘 그려졌는지를 평가하여 조금씩 수정해 가는 방법을 사용합니다.\n",
    "* 가설을 하나 세운 뒤 이 값이 주어진 요건을 충족하는지 판단하여 조금씩 변화를 주고, 이 변화가 긍정적이면 오차가 최소가 될 때까지 이 과정을 계속 반복하는 방법입니다. \n",
    "* 선을 긋고 나서 수정하는 과정에서 나중에 그린 선이 먼저 그린 선보다 더 좋은지 나쁜지를 판단하는 방법이 필요합니다.\n",
    "* 각 선의 오차를 계산할 수 있어야 하고, 오차가 작은 쪽으로 바꾸는 알고리즘이 필요합니다.\n",
    "* 기울기가 잘못되었을 수록 직선과의 거리의 합, 즉 오차의 합도 커집니다. \n",
    "* 기울기가 무한대로 커지면 오차도 무한대로 커지는 상관관계가 있습니다. \n",
    "* 오차 = 실제 값 - 예측 값\n",
    "* 오차의 합을 구할 때, 오차에 양수와 음수가 섞여 있기 때문에 오차를 단순히 더해 버리면 합이 0이 될 수도 있으므로 각 오차의 값을 제곱해 줍니다\n",
    "* 평균 제곱 오차(Mean Squared Error, MSE) - 오차 합의 평균\n",
    "* 평균 제곱근 오차(Root Mean Squared Error, RMSE) - 평균 제곱 오차는 각 오차를 제곱한 값을 사용하므로 대용량 데이터를 이용할 때는 오차가 커지고, 계산 속도가 느려지는 경우  제곱근을 씌워 줍니다.\n",
    "\n",
    "선형 회귀란 임의의 직선을 그어 이에 대한 평균 제곱근 오차를 구하고, 이 값을 가장 작게 만들어 주는 a와 b 값을 찾아가는 작업입니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 평균 제곱근 오차 구현 코드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "공부한 시간 =2, 실제점수=81, 예측점수=82\n",
      "공부한 시간 =4, 실제점수=93, 예측점수=88\n",
      "공부한 시간 =6, 실제점수=91, 예측점수=94\n",
      "공부한 시간 =8, 실제점수=97, 예측점수=100\n",
      "rmse 최종값 :3.3166247903554\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "# 기울기 a와 y 절편 b\n",
    "ab = [3,76]\n",
    "\n",
    "# x, y의 데이터 값\n",
    "data = [[2,81],[4,93],[6,91],[8,97]] #data set\n",
    "x = [ i[0] for i in data ]\n",
    "y = [ i[1] for i in data ]\n",
    "\n",
    "# y = ax + b에 a와 b 값을 대입하여 결과를 출력하는 함수\n",
    "def predict(x):\n",
    "    return ab[0]*x+ab[1]\n",
    "\n",
    "# RMSE 함수\n",
    "def rmse(p,a):\n",
    "    return np.sqrt(((p-a)**2).mean())\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# RMSE 함수를 각 y 값에 대입하여 최종 값을 구하는 함수\n",
    "def rmse_val(predict_result,y) :\n",
    "    return rmse(np.array(predict_result),np.array(y))\n",
    "\n",
    "# 예측 값이 들어갈 빈 리스트\n",
    "predict_result = []\n",
    "\n",
    "# 모든 x 값을 한 번씩 대입하여\n",
    "for i in range(len(x)):\n",
    "    predict_result.append(predict(x[i]))\n",
    "    print(\"공부한 시간 =%.f, 실제점수=%.f, 예측점수=%.f\" % (x[i],y[i],predict_result[i]))\n",
    "\n",
    "# 최종 RMSE 출력\n",
    "print(\"rmse 최종값 :\" + str(rmse_val(predict_result,y)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 오차 수정 - 경사하강법(gradient decent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
